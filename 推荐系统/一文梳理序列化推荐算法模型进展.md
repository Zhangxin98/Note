> 作者：朱勇椿
> 单位：中国科学院大学
> 研究方向：跨域推荐、多任务学习

在真实场景的推荐系统中，通常会使用所有数据来训练推荐模型，学到的user embedding可以表示用户的兴趣偏好。但是这样的用户表示可能会遗漏用户的序列行为信息，而序列推荐则旨在显式地建模用户的序列行为，提升推荐系统的效果。本期为大家分享一些序列推荐算法。

文本将序列推荐分为以下几个方面：

- 标准序列推荐
- 长短期序列推荐
- 多兴趣表示的序列推荐
- 多行为序列推荐
- 其他序列推荐

## 标准序列推荐

标准序列推荐指**通过单行为序列挖掘用户表示的推荐算法**。标准序列推荐算法也非常直接，一些常见的序列建模的方法，比如**Pooling, RNN, CNN, Memory Network, Attention, Transformer**等等。

### Pooling

将用户交互过的item的embedding，**取个均值**，作为序列特征加入推荐模型，比如google的推荐模型[1]。这种方法简单有效，也是业界最常见的使用序列特征的手段。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTCRWjolYNGLU07WjeDmBpcCsdQBiawPcezldEy7GREdBwbqB6fmXo2IQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### RNN-based

RNN是一种进行序列建模的非常使用的方法，广泛用于各种序列建模，比如文本、语音等等。GRU4Rec[2]将RNN引入了session-based推荐系统，将一个session内的交互作为序列历史，进行序列建模。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTPnBFxm3iazVDOEssb5W82N9xYVgnsjJhVEnw9YW6u79mhiaPr47djyFg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### CNN-based

TextCNN将CNN引入了序列建模，[Caser[3]](https://mp.weixin.qq.com/s/N_CDMlDDq1YMEqAp4Xw_dg)将CNN引入了序列推荐。Caser中指出现在的Markov chain models**只能建模point-level sequential patterns**，不能建模union-level patterns，而CNN可以很好的解决这个问题。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTc7MunXcnvznb5C6iacoamOhP19OspDZibpuKsib68MicaRYfibg6aQfdX4Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTkc3G7OgpichZibaib6tgrAdo6BPeG2dx6AxiaT8nh15mkmURc5f4eSyicWA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

------

**TextCNN**

> ![img](https://cdn.jsdelivr.net/gh/Zhangxin98/Note@main/img/1182656-20180919171920103-1233770993.png)
>
> TextCNN详细过程：
>
> - **Embedding**：第一层是图中最左边的7乘5的句子矩阵，每行是词向量，维度=5，这个可以类比为图像中的原始像素点。
> - **Convolution**：然后经过 kernel_sizes=(2,3,4) 的一维卷积层，每个kernel_size 有两个输出 channel。
> - **MaxPolling**：第三层是一个1-max pooling层，这样不同长度句子经过pooling层之后都能变成定长的表示。
> - **FullConnection and Softmax**：最后接一层全连接的 softmax 层，输出每个类别的概率。



### Attention-based

上述方法**没有考虑用户序列行为中哪些交互是比较重要的**，注意力机制(attention)是一个很好的解决方法。SASRec[4]提出了一种基于自注意力的序列推荐方法。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTwnILafuXiczRGtYiaHHhSZiao82IFnmzUGvicGVUTgPbMqGlPdWQryDWzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

阿里提出了一种深度注意力网络**DIN**用到推荐广告[5]，在业界有着广泛的应用。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTiae72pY44zrNYF9aaKpiaV4MeZPhPwM8FiceTP0nIB7hTZxW6HqyhJ47g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### Memory-based

上述的方法只对序列交互进行了建模，而没有存储下来，当**序列很长时可能会遗忘一些过去的交互**，RUM[6]引入了用户记忆模块，来存储序列交互的信息。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTcPIicIwFgvMqIGbicDsXLdgQFOFvUOuLJsoPBVhb7J6XGD6kGe7DMCZg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### Transformer-based

Transformer在NLP任务上取得了显著的提升，基于Transformer提出了Bert等大型预训练模型。Bert4Rec[7]将这类结构思路引入了推荐系统。“ 双向self-attention做填空题

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTCr9Xu1cicYdH6rq8KP9ZaWNrRMYgoHoP7BXXALKUgg5DYoRiaH9MQYQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 长短期序列推荐

用户可能拥有大量交互历史，**长期交互和短期交互对用户当前兴趣可能有着不同的影响**，因此有必要区分用户的长短期行为。SHAN将用户行为分为长期的和短期的，使用层次注意力网络进行建模。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMT5yMDWU3XNK13E1l45AL3xnBWVCibiaf98ECNVMCaHicUSQRt9CXF2Jwwg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 多兴趣表示的序列推荐

上述的方法通常是将用户行为编码为一个表示，但是**用户的兴趣偏好通常是多个方面的**，因此有方法将用户的序列行为编码为多个兴趣表示向量[9]。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMThGBNQBhlnvVFHFJz0enbbzkCAichiaLLib67SznsR8Eb7Ky0QLzO4Rg4w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 多行为序列推荐

**用户通常有多种不同的行为序列**，比如点击、分享、购买等等。因此对多行为序列建模来抓获用户兴趣偏好也是非常有必要的[10]。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMT78lOgdgVoPKTrfg9NTbnqicW6PPhDia4riaPQ8I1Z68BRe1gPg79wbzibw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## 其他序列推荐

现在还有一些其他的序列推荐方法，比如用**对比学习**来做序列推荐任务[11]。

![图片](https://mmbiz.qpic.cn/mmbiz_png/gUs5jjsU4qNkcIxw6hnXNjfDpcWrPPMTtaCUz1SKkibZAobVWd1guamvVoO2UK2vPj4ZI35JryWwPyQsFlQlB0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

另外还有一些和序列推荐很接近的任务，比如next basket[12]。

## 总结

显式地建模用户的历史交互行为对提升推荐的效果有很大的作用，因此需要使用一种高效的模块进行序列建模，此外还应该考虑**长短期序列、多行为序列、多兴趣表示**等多个角度的序列建模。当然在**某些场景序列特征可能作用不大**，可以先用pooling简单试试序列特征的效果。

## 参考文献

[1] Deep Neural Networks for YouTube Recommendations. Recsys2016.

[2] Session-based Recommendations with Recurrent Neural Networks. ICLR2016.

[3] Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. WSDM2018.

[4] Self-Attentive Sequential Recommendation. ICDM2018.

[5] Deep Interest Network for Click-Through Rate Prediction. KDD2018.

[6] Sequential Recommendation with User Memory Networks. WSDM2018.

[7] BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. CIKM2019.

[8] Sequential Recommender System based on Hierarchical Attention Networks. IJCAI2018.

[9] Controllable Multi-Interest Framework for Recommendation. KDD2020.

[10] Incorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation. SIGIR2021.

[11] Disentangled Self-Supervision in Sequential Recommenders. KDD2020.

[12] Factorizing Personalized Markov Chains for Next-Basket Recommendation. WWW2010.