> Distilling the Knowledge in a Neural Network
>
> Geoffrey Hinton  Google
>
> 2014 NIPS

reference：[【经典简读】知识蒸馏(Knowledge Distillation) 经典之作 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/102038521)

## 知识蒸馏的基本思路



一般来讲，越是复杂的网络，参数越多，计算量越大，其性能越好；越是小的网络，越难训练到大网络那么好的性能。或者用一些大的模型来做集成学习（例如最简单地投票）来提升整体性能。



### 提升性能和落地部署不要用相同的模型



在工作中，一般常见的开发范式是，以一个大模型结构，在很大的数据上，训练出一个性能很好的模型，然后在部署阶段，也部署这个模型以预测实际情况下的数据。作者这里认为，部署用的模型和训练提高性能用的模型，其实应用场合不一样，**用一样的模型是不对的**！应该用不一样的模型（训练用复杂大模型，目标为提高性能；而部署用小模型，目标是为了速度和节约资源），就好像很多昆虫有专门为了从环境中提取能量和营养的幼体形态和专门为了迁徙和繁殖的成虫形态一样，我们也应该用大模型来学习抽取大规模，强冗余的训练集信息，然后利用新的训练方法（这里称之为**蒸馏**）把大模型学到的知识转移到一个更适合部署的小模型上。



### 大模型的Softmax输出概率里面富含知识



这里有一个在概念上的认识障碍，就是我们通常认为模型学到的知识是体现在它学习到的具体的参数中的，而这些参数我们又很难轻易精简。我们可以从更上一层的概念想一下，其实我们学到的知识，**是一个函数，它把样本的输入向量映射到输出向量**。例如，我们的VGG模型，就是把输入的224x224x3的图片向量映射成1000维的输出的每类概率向量。而在训练VGG的过程中，我们会最大化真值那一类的概率。但是，我们模型输出的结果，还有个另外的作用，就是为不是真值的那些类也赋予了一定的概率，虽然这些概率一般比较小，但是也有些是比其他的大一些的，**这相对大小里面也包含了很多大模型学习到的信息**！比如，输入给训练好的VGG模型一个宝马轿车的泛化能力好，对未见过的样本要正确分类。然而由于条件所限，我们一般把提升模型的泛化能力这个目标简化为训练模型在训练集上对真值标签的预测能力，我们也认为，训练得到的模型对真值标签的预测能力越强，它的泛化能力也应该越强，这也是很合理的。但是，如果我们已经有了一个泛化能力很强的模型，那么为什么不去用一个小模型直接学习这个很强的模型的泛化能力呢？那不是舍本逐末吗？



### 我们要学的不是[真值标签](https://www.zhihu.com/search?q=真值标签&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A83456418})！要学的其实是泛化能力！



我们训练模型的目标函数越能反应真实场景下用户所要达到的目标越好。用户的目标是模型的泛化能力好，对未见过的样本要正确分类。然而由于条件所限，我们一般把提升模型的泛化能力这个目标简化为训练模型在训练集上对真值标签的预测能力，我们也认为，训练得到的模型对真值标签的预测能力越强，它的泛化能力也应该越强，这也是很合理的。但是，**如果我们已经有了一个泛化能力很强的模型，那么为什么不去用一个小模型直接学习这个很强的模型的泛化能力呢**？那不是舍本逐末吗？



### 怎么学习泛化能力呢？知识蒸馏！



那么问题来了。如果我们有了一个大模型，泛化能力很好，我们怎么才能让一个小模型去学习它的泛化能力呢？换句话说，怎么让大模型的泛化能力转移到小模型身上去呢？这里就用到了论文里面介绍的方法：知识蒸馏。



简单地说，知识蒸馏就是把大模型对样本输出的概率向量作为软目标“soft targets”，去让小模型的输出尽量去和这个软目标靠（原来是和One-hot编码上靠）。知识蒸馏过程所用的训练样本可以和训练大模型用的训练样本一样，或者另找一个独立的Transfer集也行。**因为“soft targets”比One-hot编码所携带的信息更多**，所以我们在**训练小模型时可以用比训练大模型时更少的训练集和更大的学习率**。



### 当“soft targets”携带信息太少怎么办？用高温T煮出来！



想象有一种情况，比如对于类似于MNIST这样的简单任务来说，大模型表现地很好，它输出的soft targets几乎和真值的One-hot编码一样（真值那一位有一个巨接近1.0的概率，其余各位概率都很小），大多数的关于大模型泛化能力的信息都集中在那些值很小的概率上。比如，某个2的测试图像，输出它是3的概率为10^-6，是7的概率为10^-9，而另外一个2的测试图像，输出它是3的概率为10^-9而是7的概率为10^-6。很显然，这些很小的概率（10^-6和10^-9）体现了两个测试图上2的写法和3更像还是和7更像，它们是携带了很重要的信息的。但是在Transfer阶段计算交叉熵的时候，由于它们的值很小，他们对于Transfer阶段的目标函数的影响很小，这是不应该的！怎么样解决这个问题呢？怎么样放大这些小概率值里面所携带的信息呢？[Caruana]([https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf](https://link.zhihu.com/?target=https%3A//www.cs.cornell.edu/~caruana/compression.kdd06.pdf))所采取的方法是用logits（Softmax的输入）作为学习的“Soft targets”（而不是前面Hinton说的Softmax的输出），然后计算大模型的logits和小模型的logits的均方差来优化小模型。而我们本文说的Hinton，用了一种更通用的称之为蒸馏的办法，**引入温度参数T去放大（蒸馏出来）这些小概率值所携带的信息**。后文我们会证明，Caruana教授的方法只是Hinton大牛方法的一个特例。



### 关于训练集



用来做知识蒸馏训练小模型的训练集合可以是无标签的数据，也可以是最初用来训练大模型的数据（反正我们要学的是模型的泛化能力，知道模型的输入输出就行了）。不过，在实际做知识蒸馏的时候，如果**有最初训练大模型的带标签的训练集训练效果会更好**，这时我们可以在训练小模型的目标函数里面加入让小模型也预测出训练样本标签的目标函数（原始目标函数是让小模型预测出大模型的输出Soft target）。而且，有时候小模型直接去学习输出Soft target有难度，加上让它去学习样本真值的损失，去诱导小模型的输出往样本真值上靠也会对学习Soft target有帮助作用。



## 蒸馏过程



![image-20211207102450397](https://cdn.jsdelivr.net/gh/Zhangxin98/Note@main/img/202112071024706.png)

![image-20211207102536506](https://cdn.jsdelivr.net/gh/Zhangxin98/Note@main/img/202112071025600.png)